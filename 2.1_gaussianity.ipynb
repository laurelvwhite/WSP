{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "# -- Uncomment following line if running in Google Colab\n",
    "#! pip install -q 'gwpy==3.0.5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties of LIGO data - Gaussianity\n",
    "\n",
    "We typically assume that LIGO data are **Gaussian**. Let's take a look at what this means. A Gaussian, also known as a \"bell curve\" or \"normal distribution,\" is a probability distribution for a random variable $x$ characterized by a mean $\\mu$ and width $\\sigma$:\n",
    "$$p(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}\\exp{\\bigg(-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}\\bigg)}$$\n",
    "Let's plot some of these distributions. Add a new cell below to define a function called `gaussian` using the equation above. We can then use this function to compute $p(x)$ for some values of $x$, $\\mu$, and $\\sigma$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mu, sigma):\n",
    "    return 1./np.sqrt(2*np.pi*sigma**2)*np.exp(-(x-mu)**2/(2*sigma**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-5, 5, 500)\n",
    "px1 = gaussian(x, 0, 1)\n",
    "px2 = gaussian(x, 0, 3)\n",
    "px3 = gaussian(x, 0, 0.3)\n",
    "px4 = gaussian(x, 2, 1)\n",
    "plt.plot(x, px1, label=r'$\\mu=0, \\sigma=1$')\n",
    "plt.plot(x, px2, label=r'$\\mu=0, \\sigma=3$')\n",
    "plt.plot(x, px3, label=r'$\\mu=0, \\sigma=0.3$')\n",
    "plt.plot(x, px4, label=r'$\\mu=2, \\sigma=1$')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('p(x)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this distribution actually tell us about the variable $x$? Let's look at an example, where $x$ represents the test scores for a class of 100 students. We generate 100 random test scores as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(1000)*7+75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mean and standard deviation of $x$, and store the mean in a variable called `mu` and the standard deviation in a variable called `sigma`. How do those values compare to the values multiplying and being added to the `randn` function? What happens if you instead generate 10,000 samples for $x$? Now let's plot a histogram of $x$, where the possible range of values of $x$ is split into bins, and the histogram shows how many of the samples from $x$ are in each bin, and add a plot of our gaussian with mean and sigma given by the values we calculated above to compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, bins, _ = plt.hist(x, bins=30, density=True)\n",
    "x_vals = np.linspace(50, 100, 100)\n",
    "plt.plot(x_vals, gaussian(x_vals, mu, sigma))\n",
    "plt.xlabel('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gaussian curve matches the histogram of the samples from $x$ very well. This shouldn't be surprising since we know we drew them from a Gaussian distribution. It turns out that LIGO data also follow a Gaussian distribution, but what are the mean and sigma for this distribution? The mean is 0, and the width is the **power spectral density**, or **PSD**. The square root of the PSD is called the amplitude spectral density, or ASD, and it can be used to generate fake LIGO data. Let's download the predicted ASD for advanced LIGO when it reaches design sensitivity, shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Amplitude Spectral Density\n",
    "![PSD](https://dcc.ligo.org/public/0149/T1800044/005/aLIGO_newDesign.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://dcc.ligo.org/public/0149/T1800044/005/aLIGODesign.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs1, asd = np.loadtxt('aLIGODesign.txt', unpack=True)\n",
    "freqs = np.arange(0, 2048, 0.25)\n",
    "asd = np.interp(freqs, freqs1, asd)\n",
    "plt.loglog(freqs, asd)\n",
    "plt.xlim(5, )\n",
    "plt.xlabel('f (Hz)')\n",
    "plt.ylabel('ASD(f)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the ASD we just downloaded looks like. Now let's generate some Gaussian data which is \"colored\" by this ASD. Remember that $h(f)$ has both real and imaginary components, so we need to generate two sets of Gaussian data independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = asd*(np.random.randn(len(asd)) + 1j*np.random.randn(len(asd)))\n",
    "plt.loglog(freqs, abs(hf))\n",
    "plt.loglog(freqs, asd)\n",
    "plt.xlim(5, )\n",
    "plt.xlabel('f [Hz]')\n",
    "plt.ylabel(r'ASD [$1/\\sqrt{\\mathrm{Hz}}$]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how this relates to the PSD that we previously learned to calculate by taking the inverse Fourier transform of the frequency series we just calculated. First, what are the times corresponding to this frequency series? Remember that the duration is given by $duration = 1/\\Delta f$, and $\\Delta t = 1/(2f_{\\max})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take the inverse Fourier transform and plot the resulting timeseries data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gwpy.frequencyseries import FrequencySeries\n",
    "hf_gwpy = FrequencySeries(hf, frequencies=freqs)\n",
    "ht_gwpy = hf_gwpy.ifft()\n",
    "ht_gwpy.plot()\n",
    "plt.ylabel('h(t)')\n",
    "print(ht_gwpy.times, times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate the PSD from the timeseries plotted above using `gwpy` as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_calc = ht_gwpy.psd(fftlength=4, method='median')\n",
    "plt.loglog(freqs, psd_calc, label='calculated')\n",
    "plt.loglog(freqs, asd**2, label='design')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PSD we used to \"color\" the data in orange lies right in the middle of the PSD calculated from the simulated data, and the simulated data looks a lot like the real data we used to compute the PSD in the previous notebook! \n",
    "\n",
    "### Challenge\n",
    "\n",
    "Now let's look at one final test of Gaussianity. Let's make a histogram of the data `hf` and fit it with a Gaussian like we did for our test set $x$ above. Calculate `mu` and `sigma` as before. You first need to whiten the **whiten** the data by dividing it by the ASD so all the frequencies can be seen on the same scale. You can do this for either the real part of the simualted data or the imaginary part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Tuto 1.2 Open Data access with GWpy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
