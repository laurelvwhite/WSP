{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "d9O1zsAO1zul"
   },
   "source": [
    "## Matched Filtering in Action for Real LIGO Data\n",
    "This tutorial is based on [Tutorial 2.2](https://github.com/gw-odw/odw-2020/blob/master/Day_2/Tuto_2.2_Matched_Filtering_In_action.ipynb) from the GW Open Data Workshop \\#3.\n",
    "\n",
    "We will be using the [PyCBC](http://github.com/ligo-cbc/pycbc) library, which is used to study gravitational-wave data, find astrophysical sources due to compact binary mergers, and study their parameters. These are some of the same tools that the LIGO and Virgo collaborations use to find gravitational waves in LIGO/Virgo data \n",
    "\n",
    "In this tutorial we will walk through how find a specific signal in LIGO data. In the last tutorial, we explored the underlying concept behind matched-filtering---the cross-correlation---and performed this operation ourselves in the time domain for simulated Gaussian noise. In this tutorial, we will use prebuilt PyCBC methods to perform the matched filtering using real LIGO data around the first detection, GW150914."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "chV5GUKV1zup"
   },
   "source": [
    "## Installation (execute only if running on a cloud platform!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "hPydO5B_1zuq",
    "outputId": "e752e5f2-dbec-4b3b-f23b-c751dbe71d91"
   },
   "outputs": [],
   "source": [
    "# -- Use the following for Google Colab\n",
    "#! pip install -q 'lalsuite==7.15' 'PyCBC==2.2.0' 'astropy==5.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "KkcI-Bah1zuw"
   },
   "source": [
    "**Important:** With Google Colab, you may need to restart the runtime after running the cell above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "cJ9NEh-q1zuw"
   },
   "source": [
    "### Looking for a specific signal in the data\n",
    "\n",
    "If you know what signal you are looking for in the data, then matched filtering is known to be the optimal method in Gaussian noise to extract the signal. Even when the parameters of the signal are unkown, you can perform the matched filtering and calculate the SNR for a range of different parameter values across the space of interest, and the template that maximizes the SNR will be the one with the parameters closest to the signal.\n",
    "\n",
    "### Preconditioning the data \n",
    " \n",
    "Since we aren't using simulated Gaussian noise anymore, we now need to precondition the data before trying to perform the matched filtering to supress low freqeuncy behavior which can introduce numerical artefacts. We will use a **high-pass** filter to remove frequency content below 15 Hz, where we know the LIGO data is affected by seismic noise. We may also wish to reduce the sample rate of the data if high frequency content is not important. PyCBC contains an interface to the online catalog of gravitational-wave data and events, so you can easily access the data and parameters of the published gravitational-wave signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "colab_type": "code",
    "id": "8VSW4sca1zuy",
    "outputId": "5bce84a1-1cd0-40d9-ffc3-c10814e3cb9c"
   },
   "outputs": [],
   "source": [
    "from pycbc.catalog import Merger\n",
    "from pycbc.filter import resample_to_delta_t, highpass\n",
    "\n",
    "# As an example, we use the GW150914 data\n",
    "merger = Merger(\"GW150914\")\n",
    "\n",
    "# Get the data from the Hanford detector\n",
    "strain = merger.strain('H1')\n",
    "\n",
    "# Remove the low frequency content and downsample the data to 2048Hz\n",
    "strain = highpass(strain, 15.0)\n",
    "strain = resample_to_delta_t(strain, 1.0/2048)\n",
    "\n",
    "plt.plot(strain.sample_times, strain)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "qqXqAIMx1zu2"
   },
   "source": [
    "#### Filter wraparound \n",
    "\n",
    "Note the spike in the data at the boundaries. This is caused by the highpass filter applied to the data. When the filter is applied to the boundaries, it wraps around to the beginning of the data. This causes issues becasue the data are not periodic. To avoid this, we trim the ends of the data sufficiently to remove the spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "colab_type": "code",
    "id": "nthrNAfz1zu2",
    "outputId": "ccc96393-caca-498b-d419-b68aa0c61bc2"
   },
   "outputs": [],
   "source": [
    "# Remove 2 seconds of data from both the beginning and end\n",
    "conditioned = strain.crop(2, 2)\n",
    "\n",
    "plt.plot(conditioned.sample_times, conditioned)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "1oVFXwS-1zu5"
   },
   "source": [
    "### Calculate the power spectral density\n",
    "As we saw in the previous notebook, one of the key steps for calculating the cross-correlation between the data and the template is to \"whiten\" both of them. To do this, we need to calculate the PSD. We can use the built-in method from PyCBC to do this, as before. Since we are using real data instead of a theoretical model for the PSD, we need to apply some extra conditioning steps to make sure the PSD is well-behaved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "lBNv_Jod1zu5"
   },
   "outputs": [],
   "source": [
    "from pycbc.psd import interpolate, inverse_spectrum_truncation\n",
    "# Estimate the power spectral density\n",
    "\n",
    "# We use 4 second samples of our time series in Welch method.\n",
    "psd1 = conditioned.psd(4)\n",
    "\n",
    "# Now that we have the PSD, we need to interpolate it to match our data\n",
    "# and then limit the filter length of 1 / PSD. After this, we can\n",
    "# directly use this PSD to filter the data in a controlled manner\n",
    "psd1 = interpolate(psd1, conditioned.delta_f)\n",
    "\n",
    "# 1/PSD will now act as a filter with an effective length of 4 seconds\n",
    "# Since the data has been highpassed above 15 Hz and will have low values\n",
    "# below this we need to inform the function to not include frequencies\n",
    "# below this frequency. \n",
    "psd1 = inverse_spectrum_truncation(psd1, int(4 * conditioned.sample_rate),\n",
    "                                  low_frequency_cutoff=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a cell below and plot the PSD to make sure it looks as expected. Remember that you can get the frequencies associated with the PSD object by using `psd.sample_frequencies`. What is happening at low frequencies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "ScKiCSQv1zu7"
   },
   "source": [
    "### Create the template\n",
    "As we saw previously, matched filtering involves computing the cross-correlation between the potential signal, or template, and the data by sliding the template across the data and summing over the product of the two.\n",
    "If there is a signal in the data that aligns with the template, you will get a large value of the cross-correlation. Let's use PyCBC to calculate our template waveform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "colab_type": "code",
    "id": "iDa3oHLc1zu8",
    "outputId": "72c63d8a-2611-47a1-bb6f-9fb5eb409a84"
   },
   "outputs": [],
   "source": [
    "from pycbc.waveform import get_td_waveform\n",
    "# In this case we \"know\" what the signal parameters are. In a search\n",
    "# we would grid over the parameters and calculate the SNR time series\n",
    "# for each one\n",
    "\n",
    "# We'll assume equal masses, and non-rotating black holes which is within the posterior probability\n",
    "# of GW150914. \n",
    "m = 36 # Solar masses\n",
    "hp, _ = get_td_waveform(approximant=\"SEOBNRv4_opt\",\n",
    "                     mass1=m,\n",
    "                     mass2=m,\n",
    "                     delta_t=conditioned.delta_t,\n",
    "                     f_lower=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we first looked at waveforms, we learned that the merger of the two black holes occurs approximately at the time corresponding to the maximum amplitude of the waveform. In the previous example of matched filtering simulated data, the peak of our cross-correlation did not occur at the time of the merger. Rather, it occured at the time corresponding to the _start_ of the signal hidden in the data. To get a better estimate of the merger time instead of the start of the signal, we need to shift the location of the merger to the end of the template. We do this below using the `cyclic_time_shift` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('Before shifting')\n",
    "plt.plot(hp.sample_times, hp)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('h(t)')\n",
    "\n",
    "template = hp.cyclic_time_shift(hp.start_time)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('After shifting')\n",
    "plt.plot(template.sample_times, template)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('h(t)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "eq3a8qI71zvB"
   },
   "source": [
    "### Calculating the cross-correlation and signal-to-noise time series\n",
    "Now we will use the tools we developed in the last notebook to calculate the cross-correlation between the data and the template. Previously, we used the maximum of the cross-correlation to calculate the SNR with which the signal is detected. We can actually calculate the SNR for all the elements of the cross-correlation array to see how it changes in time. The formula is the same, just applied to the whole array instead of just the maximum. This is called the **SNR timeseries**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The PSD, sampled properly for the signal\n",
    "psd_template = interpolate(psd1, template.delta_f)\n",
    "\n",
    "# Whiten both the conditioned data and the template\n",
    "conditioned_whitened = (conditioned.to_frequencyseries() / (psd1)**0.5).to_timeseries()\n",
    "template_whitened = (template.to_frequencyseries() / (psd_template)**0.5).to_timeseries()\n",
    "templaten = template_whitened.numpy()\n",
    "conditionedn = conditioned_whitened.numpy()\n",
    "\n",
    "# Calculate the cross-correlation, times, and SNR\n",
    "cc = np.correlate(templaten, conditionedn)\n",
    "n_shift = len(conditionedn) - len(templaten)\n",
    "dt = conditioned.delta_t\n",
    "times = np.arange(conditioned.start_time, conditioned.start_time + n_shift*dt + dt, dt)\n",
    "snr = np.absolute(cc)/np.std(cc)\n",
    "\n",
    "# Plot the SNR timeseries\n",
    "plt.plot(times, snr)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('SNR(t)')\n",
    "peak = np.argmax(snr)\n",
    "print(\"We found a signal at {}s with SNR {}\".format(times[peak], snr[peak]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PyCBC to calculate the SNR timeseries\n",
    "It turns our that there is a handy PyCBC function that can calcualte the SNR timeseries for us, which does the whitening and cross-correlation under the hood. The only difference from above is that the template needs to be the same size as the data, rather than shorter. We can get around this by \"resizing\" the template to match the data length. This amounts to adding a bunch of zeros after the end of the actual template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "5D-a0-iu1zvC",
    "outputId": "0b1c8b8a-ebbf-4007-f46f-9ea24a6a0982",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pycbc.filter import matched_filter, matched_filter_core\n",
    "\n",
    "# Make our new, longer template\n",
    "hp2, _ = get_td_waveform(approximant=\"SEOBNRv4_opt\",\n",
    "                     mass1=m,\n",
    "                     mass2=m,\n",
    "                     delta_t=conditioned.delta_t,\n",
    "                     f_lower=20)\n",
    "hp2.resize(len(conditioned))\n",
    "template2 = hp2.cyclic_time_shift(hp2.start_time)\n",
    "\n",
    "# Calculate the SNR\n",
    "snr = matched_filter(template2, conditioned, psd=psd1, low_frequency_cutoff=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at our plot of the SNR timeseries above, we can also see some spikes at times near the beginning and end of the segment. These are artifacts from filtering that we can safely remove. We also need to take the absolute value like we did above, since PyCBC doesn't do this step for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove problematic times\n",
    "snr = snr.crop(4 + 4, 4)\n",
    "\n",
    "# Take absolute value and plot\n",
    "plt.figure(figsize=[10, 4])\n",
    "plt.plot(snr.sample_times, abs(snr))\n",
    "plt.ylabel('Signal-to-noise')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.show()\n",
    "\n",
    "peak = abs(snr).numpy().argmax()\n",
    "snrp = snr[peak]\n",
    "time = snr.sample_times[peak]\n",
    "\n",
    "print(\"We found a signal at {}s with SNR {}\".format(time, abs(snrp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the time and SNR of the peak calculated with PyCBC compare with what we calculated above? The times match to within a second, but the SNR calculated by PyCBC is a bit higher. There are some extra corrections that need to be taken into account for properly normalizing the calculation and aligning the template and waveform. For this reason, we'll use the PyCBC version from now on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "IKZl57RG1zvE"
   },
   "source": [
    "### Aligning and Subtracting the Proposed Signal\n",
    "\n",
    "In the previous section, we found a peak in the signal-to-noise for a proposed binary black hole merger. We can use this SNR peak to align our template to the data, and to also subtract our template from the data. The data should be Gaussian after the signal is subtracted, as we'll be left with pure noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "iP2NKJ8h1zvF"
   },
   "outputs": [],
   "source": [
    "from pycbc.filter import sigma\n",
    "# The time, amplitude, and phase of the SNR peak tell us how to align\n",
    "# our proposed signal with the data.\n",
    "\n",
    "# Shift the template to the peak time\n",
    "dt = time - conditioned.start_time\n",
    "aligned = template2.cyclic_time_shift(dt)\n",
    "\n",
    "# scale the template so that it would have SNR 1 in this data\n",
    "aligned /= sigma(aligned, psd=psd1, low_frequency_cutoff=20.0)\n",
    "\n",
    "# Scale the template amplitude and phase to the peak value\n",
    "aligned = (aligned.to_frequencyseries() * snrp).to_timeseries()\n",
    "aligned.start_time = conditioned.start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "QZ5rXcyC1zvH"
   },
   "source": [
    "### Visualize the overlap between the signal and data\n",
    "\n",
    "To compare the data and signal on equal footing, and to concentrate on the frequency range that is important, we will whiten both the template and the data, and then **bandpass** both the data and template between 30-300 Hz. This just means that we will remove frequencies outside of this range. In this way, any signal that is in the data is transformed in the same way that the template is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "BtGiJC651zvI",
    "outputId": "680655af-d69d-4cfa-f3d1-a18266b6f206",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Whiten\n",
    "white_data = (conditioned.to_frequencyseries() / psd1**0.5).to_timeseries()\n",
    "white_template = (aligned.to_frequencyseries() / psd1**0.5).to_timeseries()\n",
    "\n",
    "# Remove excess frequencies\n",
    "white_data = white_data.highpass_fir(30., 512).lowpass_fir(300, 512)\n",
    "white_template = white_template.highpass_fir(30, 512).lowpass_fir(300, 512)\n",
    "\n",
    "# Select the time around the merger\n",
    "white_data = white_data.time_slice(merger.time-.2, merger.time+.1)\n",
    "white_template = white_template.time_slice(merger.time-.2, merger.time+.1)\n",
    "\n",
    "plt.figure(figsize=[15, 3])\n",
    "plt.plot(white_data.sample_times, white_data, label=\"Data\")\n",
    "plt.plot(white_template.sample_times, white_template, label=\"Template\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "rE7zEPsq1zvK"
   },
   "source": [
    "Similar to how we were able to see the spike in the whitened timseries in our simulated data, we can see the signal by eye in the whitened data for GW150914, too! It matches very closely with the whitened signal. The extra wiggles in the blue are just due to noise fluctuations. \n",
    "\n",
    "#### Subtracting the signal from the data\n",
    "\n",
    "Now that we've aligned the template we can simply subtract it. Let's see below how that looks in the time-frequency plots! Here the x-axis is time and the y-axis is frequency. The color corresponds to the strenght of the signal. We can see clearly the trend that the frequency of the signal increases in time. This is the characteristic \"chirp\" for binary black holes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "colab_type": "code",
    "id": "6IwKtDRz1zvK",
    "outputId": "1821dd02-59ce-4255-bf8f-d597bdecc11b"
   },
   "outputs": [],
   "source": [
    "subtracted = conditioned - aligned\n",
    "\n",
    "# Plot the original data and the subtracted signal data\n",
    "\n",
    "for data, title in [(conditioned, 'Original H1 Data'),\n",
    "                    (subtracted, 'Signal Subtracted from H1 Data')]:\n",
    "\n",
    "    t, f, p = data.whiten(4, 4).qtransform(.001,\n",
    "                                                  logfsteps=100,\n",
    "                                                  qrange=(8, 8),\n",
    "                                                  frange=(20, 512))\n",
    "    plt.figure(figsize=[15, 3])\n",
    "    plt.title(title)\n",
    "    plt.pcolormesh(t, f, p**0.5, vmin=1, vmax=6)\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.xlim(merger.time - 2, merger.time + 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "mTPmoPRV1zvM"
   },
   "source": [
    "## Challenge!\n",
    "\n",
    "Use the methods demonstrated above to see if you can calculate the SNR\n",
    "time series in the following data sets. What is the SNR of each signal?\n",
    "Which template matched best to which data?\n",
    "\n",
    "Information that may be useful:\n",
    "\n",
    "* Signals are all placed between 100 and 120 seconds into the frame file.\n",
    "* You may assume mass1 = mass1 (equal mass) and that each component mass is one of 15, 30, or 45.\n",
    "* Each file starts at gps time 0, and ends at gps time 128\n",
    "* The channel name in each file is \"H1:TEST-STRAIN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "SZYbZO9K1zvP",
    "outputId": "26434e05-56bf-4880-8f9d-41f27fd81f32"
   },
   "outputs": [],
   "source": [
    "# Download the challenge set files\n",
    "from pycbc.frame import read_frame\n",
    "import urllib\n",
    "\n",
    "def get_file(fname):\n",
    "    url = \"https://github.com/gw-odw/odw-2020/raw/master/Data/{}\"\n",
    "    url = url.format(fname)\n",
    "    urllib.request.urlretrieve(url, fname)\n",
    "    print('Getting : {}'.format(url))\n",
    "\n",
    "files = ['PyCBC_T2_0.gwf', 'PyCBC_T2_1.gwf', 'PyCBC_T2_2.gwf']\n",
    "\n",
    "for fname in files:\n",
    "    get_file(fname)    \n",
    "\n",
    "# An example of how to read the data from these files:\n",
    "file_name = \"PyCBC_T2_0.gwf\"\n",
    "\n",
    "# A channel name is needed since often `gwf` files contain \n",
    "# many different data sets.\n",
    "channel_name = \"H1:TEST-STRAIN\"\n",
    "\n",
    "start = 0\n",
    "end = start + 128\n",
    "\n",
    "ts = read_frame(file_name, channel_name, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Tuto_2.2_Matched_Filtering_In_action.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
